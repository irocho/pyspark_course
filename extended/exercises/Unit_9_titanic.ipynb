{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will be faced with the legendary Titanic competition from Kaggle:\n",
    "* [The legendary Titanic ML competition](https://www.kaggle.com/competitions/titanic)\n",
    "\n",
    "The purpose of the competition is simple: create a model that can predict which passengers survived the Titanic shipwreck. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "For this we have to our disposal a dataset with the following variables:\n",
    "\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|----------|------------|-----|\n",
    "|survival|Survival| 0 = No, 1 = Yes|\n",
    "|pclass|Ticket class| 1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex|Sex||\n",
    "|Age |Age in years||\n",
    "|sibsp|# of siblings / spouses aboard the Titanic||\n",
    "|parch|# of parents / children aboard the Titanic||\n",
    "|ticket|Ticket number ||\n",
    "|fare|Passenger fare ||\n",
    "|cabin|Cabin number||\n",
    "|embarked|Port of Embarkation |C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "- pclass: A proxy for socio-economic status (SES)\n",
    " - 1st = Upper\n",
    " - 2nd = Middle\n",
    " - 3rd = Lower\n",
    "- age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "- sibsp: The dataset defines family relations in this way...\n",
    "- Sibling = brother, sister, stepbrother, stepsister\n",
    "- Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "- parch: The dataset defines family relations in this way...\n",
    "- Parent = mother, father\n",
    "- Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "We have to start downloading the data. It is available under the data tab.\n",
    "\n",
    "* [The legendary Titanic ML competition](https://www.kaggle.com/c/titanic)\n",
    "\n",
    "We will need the following files that are in CSV format:\n",
    "- train.csv\n",
    "- test.csv\n",
    "\n",
    "Then we have to upload the files to HDFS, to the `datasets/titanic` directory.\n",
    "\n",
    "As you can see the data have been already splitted in the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now now load the data and explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers = spark.read.csv('datasets/titanic/train.csv', header=True,\n",
    "                       inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passengers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passengers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep feature engineering simple we will select the following features:\n",
    "- Age: probably children should be given priority\n",
    "- Pclass: the ticket class is a proxy for socio-economic status, so we would expect that this could have an impact\n",
    "- Sex: the gender could have an impact, because usually women and children are given priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Sex variable we will need a StringIndexer Estimator to convert gender to a numeric index so we can use it as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='Sex_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to assemble the selected features into a vector to use it with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Sex_feature', 'Pclass', 'Age'], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our previous exploration of the first 20 rows we see that there are some null values in the Sex column, so we have to filter them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.where(col('Age').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_not_null = passengers.where(col('Age').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers_not_null.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the classification we will use a simple LogisticRegression as the Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[sex_indexer, assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 'label' column in this case we can use the 'Survived' column, so we rename it, alternatively we could also pass the `labelCol='Survived'` argument to the LogisticRegression Estimator. For optimization, it is also good to include only the columns that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = passengers_not_null.select('Sex', 'Age', 'Pclass', 'Survived').withColumnRenamed('Survived', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+-----+\n",
      "|   Sex| Age|Pclass|label|\n",
      "+------+----+------+-----+\n",
      "|  male|22.0|     3|    0|\n",
      "|female|38.0|     1|    1|\n",
      "|female|26.0|     3|    1|\n",
      "|female|35.0|     1|    1|\n",
      "|  male|35.0|     3|    0|\n",
      "+------+----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 1.93 ms, total: 30.4 ms\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+-----+\n",
      "|   Sex|Age|Pclass|label|\n",
      "+------+---+------+-----+\n",
      "|female|2.0|     3|    0|\n",
      "|female|4.0|     2|    1|\n",
      "|female|4.0|     3|    1|\n",
      "|female|5.0|     3|    1|\n",
      "|female|5.0|     3|    1|\n",
      "+------+---+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+-----+-----------+-------------+--------------------+--------------------+----------+\n",
      "|   Sex|Age|Pclass|label|Sex_feature|     features|       rawPrediction|         probability|prediction|\n",
      "+------+---+------+-----+-----------+-------------+--------------------+--------------------+----------+\n",
      "|female|2.0|     3|    0|        1.0|[1.0,3.0,2.0]|[-0.8537807848214...|[0.29864035352784...|       1.0|\n",
      "|female|4.0|     2|    1|        1.0|[1.0,2.0,4.0]|[-1.9050655503900...|[0.12953622750151...|       1.0|\n",
      "|female|4.0|     3|    1|        1.0|[1.0,3.0,4.0]|[-0.7971010986774...|[0.31064596322945...|       1.0|\n",
      "|female|5.0|     3|    1|        1.0|[1.0,3.0,5.0]|[-0.7687612556055...|[0.31674713244972...|       1.0|\n",
      "|female|5.0|     3|    1|        1.0|[1.0,3.0,5.0]|[-0.7687612556055...|[0.31674713244972...|       1.0|\n",
      "+------+---+------+-----+-----------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aur = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963585434173672"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 s, sys: 416 ms, total: 2.15 s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(lr.regParam, [0.0, 0.01, 0.1, 1.0]) \\\n",
    "            .addGrid(lr.maxIter, [10, 20, 50]) \\\n",
    "            .build()\n",
    "            \n",
    "cv = (CrossValidator()\n",
    "      .setEstimator(pipeline)\n",
    "      .setEvaluator(evaluator)\n",
    "      .setEstimatorParamMaps(param_grid)\n",
    "      .setNumFolds(3))\n",
    "\n",
    "cv_model = cv.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = cv_model.transform(test)\n",
    "new_aur = evaluator.evaluate(new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989262371615314"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_aur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just a quick and simple solution but you can definitely improve this!!\n",
    "\n",
    "You can also upload your results to kaggle and take part in the competition:\n",
    "```\n",
    "You should submit a csv file with exactly 418 entries plus a header row.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "    PassengerId (sorted in any order)\n",
    "    Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_test = spark.read.csv('datasets/titanic/test.csv', header=True,\n",
    "                       inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv_model.transform(competition_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = result.select('PassengerId', 'prediction').withColumnRenamed('prediction', 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|     0.0|\n",
      "|        893|     0.0|\n",
      "|        894|     0.0|\n",
      "|        895|     0.0|\n",
      "|        896|     1.0|\n",
      "+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to create the CSV file with the required header, but to our surprise this will return an errror (try to uncomment and run the command below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit.write.csv('results_titanic', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatelly it encounters null values and fails to proceed. Let's try to find where they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.where(col('Survived').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.where(col('PassengerId').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_test.where(col('Age').isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have null values in the column 'Age' but our pipeline discarded those values, so there is now an issue because our pipeline does not support this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One quick solution is to replace those 'Age' null values with for example 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_test_age_fixed = competition_test.na.fill({'Age': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv_model.transform(competition_test_age_fixed)\n",
    "submit = result.select('PassengerId', 'prediction').withColumnRenamed('prediction', 'Survived')\n",
    "submit.write.mode('overwrite').csv('results_titanic', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now download and review the final csv file and add the header row before submitting.\n",
    "\n",
    "```\n",
    "hdfs dfs -get results_titanic\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
