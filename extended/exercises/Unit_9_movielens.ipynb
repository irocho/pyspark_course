{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you are going to build a movie recommender system.\n",
    "\n",
    "To train it we will use the MovieLens dataset.\n",
    "- [MovieLens Datasets](https://grouplens.org/datasets/movielens/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering\n",
    "Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix. spark.ml currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. spark.ml uses the alternating least squares (ALS) algorithm to learn these latent factors. The implementation in spark.ml has the following parameters:\n",
    "\n",
    "-    numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n",
    "-    rank is the number of latent factors in the model (defaults to 10).\n",
    "-    maxIter is the maximum number of iterations to run (defaults to 10).\n",
    "-    regParam specifies the regularization parameter in ALS (defaults to 1.0).\n",
    "-    implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "-    alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).\n",
    "-    nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false).\n",
    "\n",
    "Note: The DataFrame-based API for ALS currently only supports integers for user and item ids. Other numeric types are supported for the user and item id columns, but the ids must be within the integer value range.\n",
    "\n",
    "You can find all the details here:\n",
    "- [Spark Collaborative Filtering Guide](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lab we will use the \"Small\" dataset from \"MovieLens Latest Datasets\", but you can then experiment with the larger ones.\n",
    "\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files links.csv, movies.csv, ratings.csv and tags.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "ratings.csv:\n",
    "- userId\n",
    "- movieId\n",
    "- rating: Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars)\n",
    "- timestamp: Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n",
    "movies.csv:\n",
    "- movieId\n",
    "- title\n",
    "- genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "We have to start downloading the data. It is available under the data tab.\n",
    "\n",
    "* [ml-latest-small](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip)\n",
    "\n",
    "We will need the following files that are in CSV format:\n",
    "- ratings.csv\n",
    "- movies.csv\n",
    "\n",
    "Then we have to upload the files to HDFS, to the `datasets/movielens-latest-small` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now now load the data and explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.csv('datasets/movielens-latest-small/ratings.csv', header=True,\n",
    "                         inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.createOrReplaceTempView('ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.csv('datasets/movielens-latest-small/movies.csv', header=True,\n",
    "                         inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.createOrReplaceTempView('movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, title: string, genres: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.cache()\n",
    "movies.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|            100836|\n",
      "|   mean| 3.501556983616962|\n",
      "| stddev|1.0425292390606342|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.select('rating').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For curiosity let's see what are the users with the highest number of reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   414| 2698|\n",
      "|   599| 2478|\n",
      "|   474| 2108|\n",
      "|   448| 1864|\n",
      "|   274| 1346|\n",
      "|   610| 1302|\n",
      "|    68| 1260|\n",
      "|   380| 1218|\n",
      "|   606| 1115|\n",
      "|   288| 1055|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select userId, count(*) as count from ratings group by userId order by count desc limit 10''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incredible! There are users that have seen thousands of films and created reviews about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which films have the highest number of reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    356|  329|\n",
      "|    318|  317|\n",
      "|    296|  307|\n",
      "|    593|  279|\n",
      "|   2571|  278|\n",
      "|    260|  251|\n",
      "|    480|  238|\n",
      "|    110|  237|\n",
      "|    589|  224|\n",
      "|    527|  220|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select movieId, count(*) as count from ratings group by movieId order by count desc limit 10''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually it would be much more interesting to see the title of the film:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "| Forrest Gump (1994)|  329|\n",
      "|Shawshank Redempt...|  317|\n",
      "| Pulp Fiction (1994)|  307|\n",
      "|Silence of the La...|  279|\n",
      "|  Matrix, The (1999)|  278|\n",
      "|Star Wars: Episod...|  251|\n",
      "|Jurassic Park (1993)|  238|\n",
      "|   Braveheart (1995)|  237|\n",
      "|Terminator 2: Jud...|  224|\n",
      "|Schindler's List ...|  220|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select movies.title, count(*) as count\n",
    "             from ratings inner join movies \n",
    "             on ratings.movieId=movies.movieId \n",
    "             group by movies.title\n",
    "             order by count desc limit 10''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are dealing with a collaborative filtering problem so we will use the ALS Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `coldStartStrategy='drop'` to ensure we don't have issues during evaluation with NaN metrics.\n",
    "\n",
    "```\n",
    "When making predictions using an ALS model, it is common to encounter users and/or items in the test dataset that were not present during training the model. \n",
    "\n",
    "By default, Spark assigns NaN predictions during ALSModel.transform when a user and/or item factor is not present in the model. \n",
    "\n",
    "However, this is undesirable during cross-validation, since any NaN predicted values will result in NaN results for the evaluation metric (for example when using RegressionEvaluator). This makes model selection impossible.\n",
    "\n",
    "Spark allows users to set the coldStartStrategy parameter to “drop” in order to drop any rows in the DataFrame of predictions that contain NaN values.\n",
    "\n",
    "Currently the supported cold start strategies are “nan” (the default behavior mentioned above) and “drop”. Further strategies may be supported in future.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.84 ms, sys: 2.61 ms, total: 11.5 ms\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   409|    471|   3.0| 967912821| 3.3105135|\n",
      "|   372|    471|   3.0| 874415126|  1.962655|\n",
      "|   387|    471|   3.0|1139047519| 3.3807425|\n",
      "|   555|    471|   3.0| 978746933|  3.146028|\n",
      "|   216|    471|   3.0| 975212641| 2.9404469|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root-mean squared error (RMSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0872392249023355"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in general a estimation of our average error is around 1 star."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate top 5 movie recommendations for each user:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods in the ALS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ALS Estimator has some usefult methods to simplify the generation of recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each user generate his/her top 5 movie recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_per_user = model.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[70946, 12.38880...|\n",
      "|   463|[[80906, 6.749953...|\n",
      "+------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations_per_user.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each movie recommend the top 5 users that would enjoy it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_per_movie = model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[498, 5.9596877]...|\n",
      "|   4900|[[126, 6.972471],...|\n",
      "+-------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations_per_movie.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate top 5 movie recommendations for a specific group of users.**\n",
    "\n",
    "The `users` variable must contain a DataFrame containing a column of user ids. The column name must match `userCol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = spark.createDataFrame([Row(userId=414), Row(userId=599)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|   414|\n",
      "|   599|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_for_user_group = model.recommendForUserSubset(users, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   599|[[3089, 4.9771776...|\n",
      "|   414|[[89904, 5.474591...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations_for_user_group.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate top 5 user recommendations for a specific set of movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_movies = spark.createDataFrame([Row(movieId=356), Row(movieId=318)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_for_selected_movies = model.recommendForItemSubset(selected_movies, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    318|[[429, 5.7827845]...|\n",
      "|    356|[[429, 5.533156],...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations_for_selected_movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For fun: let's add your movie preferences and see what you get as recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which user ids are taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|min|max|\n",
      "+---+---+\n",
      "|  1|610|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.select(min(col('userId')).alias('min'), max(col('userId')).alias('max')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|min|max|\n",
      "+---+---+\n",
      "|  1|610|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.select(min(col('userId')).alias('min'), max(col('userId')).alias('max')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could just use the `describe` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            userId|\n",
      "+-------+------------------+\n",
      "|  count|            100836|\n",
      "|   mean|326.12756356856676|\n",
      "| stddev| 182.6184914635004|\n",
      "|    min|                 1|\n",
      "|    max|               610|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.describe('userId').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will take the userId 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some movie titles to generate our reviews. Let's imagine that we are some sort of Harry Potter's fans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4896</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5816</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8368</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (2004)</td>\n",
       "      <td>Adventure|Fantasy|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40815</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (2005)</td>\n",
       "      <td>Adventure|Fantasy|Thriller|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54001</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (2007)</td>\n",
       "      <td>Adventure|Drama|Fantasy|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69844</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (2009)</td>\n",
       "      <td>Adventure|Fantasy|Mystery|Romance|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81834</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1 (...</td>\n",
       "      <td>Action|Adventure|Fantasy|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88125</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2 (...</td>\n",
       "      <td>Action|Adventure|Drama|Fantasy|Mystery|IMAX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title  \\\n",
       "0     4896  Harry Potter and the Sorcerer's Stone (a.k.a. ...   \n",
       "1     5816     Harry Potter and the Chamber of Secrets (2002)   \n",
       "2     8368    Harry Potter and the Prisoner of Azkaban (2004)   \n",
       "3    40815         Harry Potter and the Goblet of Fire (2005)   \n",
       "4    54001   Harry Potter and the Order of the Phoenix (2007)   \n",
       "5    69844      Harry Potter and the Half-Blood Prince (2009)   \n",
       "6    81834  Harry Potter and the Deathly Hallows: Part 1 (...   \n",
       "7    88125  Harry Potter and the Deathly Hallows: Part 2 (...   \n",
       "\n",
       "                                        genres  \n",
       "0                   Adventure|Children|Fantasy  \n",
       "1                            Adventure|Fantasy  \n",
       "2                       Adventure|Fantasy|IMAX  \n",
       "3              Adventure|Fantasy|Thriller|IMAX  \n",
       "4                 Adventure|Drama|Fantasy|IMAX  \n",
       "5       Adventure|Fantasy|Mystery|Romance|IMAX  \n",
       "6                Action|Adventure|Fantasy|IMAX  \n",
       "7  Action|Adventure|Drama|Fantasy|Mystery|IMAX  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.where(col('title').like('Harry Potter%')).limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prefs = spark.createDataFrame([\n",
    "    Row(userId=1000, movieId=4896, rating=5.0),\n",
    "    Row(userId=1000, movieId=5816, rating=5.0),\n",
    "    Row(userId=1000, movieId=8368, rating=5.0),\n",
    "    Row(userId=1000, movieId=40815, rating=5.0),\n",
    "    Row(userId=1000, movieId=54001, rating=5.0),\n",
    "    Row(userId=1000, movieId=69844, rating=5.0),\n",
    "    Row(userId=1000, movieId=81834, rating=5.0),\n",
    "    Row(userId=1000, movieId=88125, rating=5.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieId|rating|userId|\n",
      "+-------+------+------+\n",
      "|   4896|   5.0|  1000|\n",
      "|   5816|   5.0|  1000|\n",
      "|   8368|   5.0|  1000|\n",
      "|  40815|   5.0|  1000|\n",
      "|  54001|   5.0|  1000|\n",
      "|  69844|   5.0|  1000|\n",
      "|  81834|   5.0|  1000|\n",
      "|  88125|   5.0|  1000|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_prefs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of the timestamp column that we do not use (so we do not have to specify it in `my_prefs`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_new = training.drop('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the new training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_extended = training_new.unionByName(my_prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Take into account that if you use `union` instead of `unionByName`: Also as standard in SQL, this function resolves columns by position (not by name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80561"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80569"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_extended.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|  1000|   4896|   5.0|\n",
      "|  1000|   5816|   5.0|\n",
      "|  1000|   8368|   5.0|\n",
      "|  1000|  40815|   5.0|\n",
      "|  1000|  54001|   5.0|\n",
      "|  1000|  69844|   5.0|\n",
      "|  1000|  81834|   5.0|\n",
      "|  1000|  88125|   5.0|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_extended.where('userId = 1000').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we re-traing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 24.3 ms, total: 66 ms\n",
      "Wall time: 5.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_new = als.fit(training_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's find what we get as recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user = spark.createDataFrame([Row(userId=1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 ms, sys: 447 µs, total: 1.58 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = model_new.recommendForUserSubset(my_user, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Look at the Wall time and you notice how the `recommendForUserSubset` is not called until we try to retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.7 ms, sys: 64.4 ms, total: 161 ms\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_recommendations = results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1000, recommendations=[Row(movieId=5690, rating=6.74323034286499), Row(movieId=1280, rating=6.063719749450684), Row(movieId=3181, rating=6.059947967529297), Row(movieId=27611, rating=6.056857109069824), Row(movieId=1299, rating=5.9727630615234375), Row(movieId=4642, rating=5.9463348388671875), Row(movieId=2730, rating=5.933717727661133), Row(movieId=83803, rating=5.889867782592773), Row(movieId=3508, rating=5.886873245239258), Row(movieId=47423, rating=5.8755340576171875)])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can get the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(title=u'Grave of the Fireflies (Hotaru no haka) (1988)')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.where(col('movieId')==5690).select('title').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5690 Grave of the Fireflies (Hotaru no haka) (1988) 6.74323034286\n",
      "1280 Raise the Red Lantern (Da hong deng long gao gao gua) (1991) 6.06371974945\n",
      "3181 Titus (1999) 6.05994796753\n",
      "27611 Battlestar Galactica (2003) 6.05685710907\n",
      "1299 Killing Fields, The (1984) 5.97276306152\n",
      "4642 Hedwig and the Angry Inch (2000) 5.94633483887\n",
      "2730 Barry Lyndon (1975) 5.93371772766\n",
      "83803 Day & Night (2010) 5.88986778259\n",
      "3508 Outlaw Josey Wales, The (1976) 5.88687324524\n",
      "47423 Half Nelson (2006) 5.87553405762\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "for m in my_recommendations[0].recommendations:\n",
    "    title = movies.where(col('movieId')==m.movieId).select('title').collect()[0].title\n",
    "    print(m.movieId, title, m.rating)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that bad, but just as curiosity, let's check if we have the 'Fantastic Beasts' saga also from J. K. Rowling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------+-------+\n",
      "|movieId|title                                         |genres |\n",
      "+-------+----------------------------------------------+-------+\n",
      "|135143 |Fantastic Beasts and Where to Find Them (2016)|Fantasy|\n",
      "+-------+----------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.where(col('title').like('Fantastic Beasts%')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|    50| 135143|   2.0|1514239413|\n",
      "|    62| 135143|   4.0|1521489754|\n",
      "|    68| 135143|   4.0|1526947551|\n",
      "|    98| 135143|   2.5|1532457800|\n",
      "|   125| 135143|   3.5|1480789755|\n",
      "|   210| 135143|   4.5|1517086938|\n",
      "|   212| 135143|   4.5|1527796007|\n",
      "|   318| 135143|   4.5|1512681753|\n",
      "|   352| 135143|   4.0|1493931961|\n",
      "|   380| 135143|   4.0|1493473809|\n",
      "|   382| 135143|   4.0|1515162207|\n",
      "|   517| 135143|   3.5|1487966240|\n",
      "|   551| 135143|   3.0|1504320996|\n",
      "|   596| 135143|   3.5|1535627421|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.where('movieId = 135143').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is one of those films in the dataset.\n",
    "\n",
    "Too bad we did not get it in the recommendations!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
