{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing KMeans (optimized version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters to find\n",
    "K = 5\n",
    "# Convergence threshold\n",
    "THRESHOLD = 0.1\n",
    "# Maximum number of iterations\n",
    "MAX_ITERS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coordinates(line):\n",
    "    fields = line.split(',')\n",
    "    return (float(fields[3]), float(fields[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile('datasets/locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = data.map(parse_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **cache the points** because the algorithm will be reusing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1, p2):  \n",
    "    \"Calculate the squared distance between two given points\"\n",
    "    return (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2\n",
    "\n",
    "def closest_centroid(point, centroidsBC):    \n",
    "    \"Calculate the closest centroid to the given point: eg. the cluster this point belongs to\"\n",
    "    distances = [distance(point, c) for c in centroidsBC.value]\n",
    "    shortest = min(distances)\n",
    "    return distances.index(shortest)\n",
    "\n",
    "def add_points(p1,p2):\n",
    "    \"Add two points of the same cluster in order to calculate later the new centroids\"\n",
    "    return [p1[0] + p2[0], p1[1] + p2[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively calculate the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation in iteration 0: 4989.32008451\n",
      "Variation in iteration 1: 2081.17551268\n",
      "Variation in iteration 2: 1.6011620119\n",
      "Variation in iteration 3: 2.55059475168\n",
      "Variation in iteration 4: 0.994848416636\n",
      "Variation in iteration 5: 0.0381850235415\n",
      "Final centroids: [[35.08592000544936, -112.57643826547803], [0.0, 0.0], [38.05200414101911, -121.20324355675143], [43.891507710205694, -121.32350131512835], [34.28939789970032, -117.77840744773651]]\n",
      "CPU times: user 84 ms, sys: 26.9 ms, total: 111 ms\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initial centroids: we just take K randomly selected points\n",
    "centroids = points.takeSample(False, K, 42)\n",
    "# Broadcast var\n",
    "centroidsBC = sc.broadcast(centroids)\n",
    "\n",
    "# Just make sure the first iteration is always run\n",
    "variation = THRESHOLD + 1\n",
    "iteration = 0\n",
    "\n",
    "while variation > THRESHOLD  and iteration < MAX_ITERS:\n",
    "     # Map each point to (centroid, (point, 1))\n",
    "    with_centroids = points.map(lambda p : (closest_centroid(p, centroidsBC), (p, 1)))\n",
    "    # For each centroid reduceByKey adding the coordinates of all the points\n",
    "    # and keeping track of the number of points\n",
    "    cluster_stats = with_centroids.reduceByKey(lambda (p1, n1), (p2, n2):  (add_points(p1, p2), n1 + n2))\n",
    "    # For each existing centroid find the new centroid location calculating the average of each closest point\n",
    "    new_centroids = cluster_stats.map(lambda (c, ((x, y), n)): (c, [x/n, y/n])).collect()\n",
    "    # Calculate the variation between old and new centroids\n",
    "    variation = 0\n",
    "    for  (c, point) in new_centroids: variation += distance(centroids[c], point)\n",
    "    print('Variation in iteration {}: {}'.format(iteration, variation))\n",
    "    # Replace old centroids with the new values\n",
    "    for (c, point) in new_centroids: centroids[c] = point\n",
    "    # Replace the centroids broadcast var with the new values\n",
    "    centroidsBC = sc.broadcast(centroids)\n",
    "    iteration += 1\n",
    "        \n",
    "print('Final centroids: {}'.format(centroids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
